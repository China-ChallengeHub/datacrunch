{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare LGB for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGBM'...\n",
      "remote: Enumerating objects: 20455, done.\u001b[K\n",
      "remote: Total 20455 (delta 0), reused 0 (delta 0), pack-reused 20455\u001b[K\n",
      "Receiving objects: 100% (20455/20455), 16.07 MiB | 12.52 MiB/s, done.\n",
      "Resolving deltas: 100% (14922/14922), done.\n",
      "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
      "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
      "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
      "Cloning into '/kaggle/working/LightGBM/compute'...\n",
      "remote: Enumerating objects: 21728, done.        \n",
      "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
      "Receiving objects: 100% (21728/21728), 8.51 MiB | 15.07 MiB/s, done.\n",
      "Resolving deltas: 100% (17565/17565), done.\n",
      "Cloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser'...\n",
      "remote: Enumerating objects: 126, done.        \n",
      "remote: Counting objects: 100% (126/126), done.        \n",
      "remote: Compressing objects: 100% (80/80), done.        \n",
      "remote: Total 626 (delta 60), reused 69 (delta 26), pack-reused 500        \n",
      "Receiving objects: 100% (626/626), 789.08 KiB | 3.09 MiB/s, done.\n",
      "Resolving deltas: 100% (314/314), done.\n",
      "Cloning into '/kaggle/working/LightGBM/external_libs/fmt'...\n",
      "remote: Enumerating objects: 19, done.        \n",
      "remote: Counting objects: 100% (19/19), done.        \n",
      "remote: Compressing objects: 100% (14/14), done.        \n",
      "remote: Total 24243 (delta 5), reused 13 (delta 2), pack-reused 24224        \n",
      "Receiving objects: 100% (24243/24243), 11.88 MiB | 17.06 MiB/s, done.\n",
      "Resolving deltas: 100% (16419/16419), done.\n",
      "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
      "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
      "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
      "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
      "Cloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
      "remote: Enumerating objects: 81, done.        \n",
      "remote: Counting objects: 100% (81/81), done.        \n",
      "remote: Compressing objects: 100% (75/75), done.        \n",
      "remote: Total 13378 (delta 29), reused 57 (delta 5), pack-reused 13297        \n",
      "Receiving objects: 100% (13378/13378), 8.77 MiB | 14.37 MiB/s, done.\n",
      "Resolving deltas: 100% (10117/10117), done.\n",
      "Cloning into '/kaggle/working/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
      "remote: Enumerating objects: 4, done.        \n",
      "remote: Counting objects: 100% (4/4), done.        \n",
      "remote: Compressing objects: 100% (4/4), done.        \n",
      "remote: Total 1160 (delta 0), reused 0 (delta 0), pack-reused 1156        \n",
      "Receiving objects: 100% (1160/1160), 7.01 MiB | 1.22 MiB/s, done.\n",
      "Resolving deltas: 100% (772/772), done.\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
      "Submodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n"
     ]
    }
   ],
   "source": [
    "!rm -r /opt/conda/lib/python3.7/site-packages/lightgbm\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y -qq libboost-all-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Looking for CL_VERSION_2_2\n",
      "-- Looking for CL_VERSION_2_2 - not found\n",
      "-- Looking for CL_VERSION_2_1\n",
      "-- Looking for CL_VERSION_2_1 - not found\n",
      "-- Looking for CL_VERSION_2_0\n",
      "-- Looking for CL_VERSION_2_0 - not found\n",
      "-- Looking for CL_VERSION_1_2\n",
      "-- Looking for CL_VERSION_1_2 - found\n",
      "-- Found OpenCL: /usr/local/cuda/lib64/libOpenCL.so (found version \"1.2\") \n",
      "-- OpenCL include directory: /usr/local/cuda/include\n",
      "-- Boost 1.56.0 found.\n",
      "-- Found Boost components:\n",
      "   filesystem;system\n",
      "-- Performing Test MM_PREFETCH\n",
      "-- Performing Test MM_PREFETCH - Success\n",
      "-- Using _mm_prefetch\n",
      "-- Performing Test MM_MALLOC\n",
      "-- Performing Test MM_MALLOC - Success\n",
      "-- Using _mm_malloc\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /kaggle/working/LightGBM/build\n",
      "Scanning dependencies of target _lightgbm\n",
      "Scanning dependencies of target lightgbm\n",
      "[  2%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\n",
      "[  2%] Building CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\n",
      "[  4%] Building CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\n",
      "[  5%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\n",
      "[  7%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\n",
      "[  8%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n",
      "[ 10%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\n",
      "[ 11%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n",
      "[ 13%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n",
      "[ 14%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n",
      "[ 16%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\n",
      "[ 17%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n",
      "[ 19%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n",
      "[ 20%] Building CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\n",
      "[ 22%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\n",
      "[ 23%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\n",
      "[ 25%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\n",
      "[ 26%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\n",
      "[ 28%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\n",
      "[ 29%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\n",
      "[ 31%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\n",
      "[ 32%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\n",
      "[ 34%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\n",
      "[ 35%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\n",
      "[ 37%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\n",
      "[ 38%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\n",
      "[ 40%] Building CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\n",
      "[ 41%] Building CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\n",
      "[ 43%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\n",
      "[ 44%] Building CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\n",
      "[ 46%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\n",
      "[ 47%] Building CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\n",
      "[ 49%] Building CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\n",
      "[ 50%] Building CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\n",
      "[ 52%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\n",
      "[ 53%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\n",
      "[ 55%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\n",
      "[ 56%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\n",
      "[ 58%] Building CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\n",
      "[ 59%] Building CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\n",
      "[ 61%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\n",
      "[ 62%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\n",
      "[ 64%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\n",
      "[ 65%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\n",
      "[ 67%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\n",
      "[ 68%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n",
      "[ 70%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
      "[ 71%] Building CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\n",
      "[ 73%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\n",
      "[ 74%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\n",
      "[ 76%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\n",
      "[ 77%] Building CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\n",
      "[ 79%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n",
      "[ 80%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
      "[ 82%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
      "[ 83%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
      "[ 85%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
      "[ 86%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
      "[ 88%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n",
      "[ 89%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n",
      "[ 91%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\n",
      "[ 92%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\n",
      "[ 94%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
      "[ 95%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
      "[ 97%] Building CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\n",
      "[ 98%] Linking CXX executable ../lightgbm\n",
      "[ 98%] Built target lightgbm\n",
      "[100%] Linking CXX shared library ../lib_lightgbm.so\n",
      "[100%] Built target _lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'build': No such file or directory\n",
      "cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n",
      "/usr/bin/cmake: /opt/conda/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd LightGBM\n",
    "rm -r build\n",
    "mkdir build\n",
    "cd build\n",
    "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
    "make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/lightgbm\n",
      "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "running egg_info\n",
      "creating lightgbm.egg-info\n",
      "writing lightgbm.egg-info/PKG-INFO\n",
      "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "writing requirements to lightgbm.egg-info/requires.txt\n",
      "writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "no previously-included directories found matching 'build'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching '*.txt'\n",
      "warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "warning: no files found matching 'compile/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/CMakeIntegratedOpenCL.cmake'\n",
      "warning: no files found matching '*.so' under directory 'compile'\n",
      "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "warning: no files found matching 'compile/compute/CMakeLists.txt'\n",
      "warning: no files found matching '*' under directory 'compile/compute/cmake'\n",
      "warning: no files found matching '*' under directory 'compile/compute/include'\n",
      "warning: no files found matching '*' under directory 'compile/compute/meta'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
      "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
      "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
      "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
      "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
      "warning: no files found matching '*' under directory 'compile/include'\n",
      "warning: no files found matching '*' under directory 'compile/src'\n",
      "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
      "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
      "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "warning: no previously-included files found matching 'compile/compute/.git'\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "running install_lib\n",
      "creating /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/sklearn.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/compat.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/callback.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/engine.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/__init__.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/VERSION.txt -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/basic.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/libpath.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying build/lib/lightgbm/plotting.py -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "copying ../lib_lightgbm.so -> /opt/conda/lib/python3.7/site-packages/lightgbm\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/compat.py to compat.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/callback.py to callback.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/engine.py to engine.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/basic.py to basic.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n",
      "byte-compiling /opt/conda/lib/python3.7/site-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n",
      "running install_egg_info\n",
      "Copying lightgbm.egg-info to /opt/conda/lib/python3.7/site-packages/lightgbm-3.1.1.99-py3.7.egg-info\n",
      "running install_scripts\n"
     ]
    }
   ],
   "source": [
    "!cd LightGBM/python-package/;python3 setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!rm -r LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lib & Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import requests\n",
    "from scipy import stats\n",
    "\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(y_true, y_pred):\n",
    "    return (stats.spearmanr(y_true, y_pred))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_datalink = '/kaggle/input/datacrunch/train_test_hackathon.csv'\n",
    "hackathon_data_link = '/kaggle/input/datacrunch/hackathon_data.csv'\n",
    "\n",
    "# Data for training\n",
    "train_df = pd.read_csv(train_datalink)\n",
    "\n",
    "# Data for which you will submit your prediction\n",
    "test_df = pd.read_csv(hackathon_data_link)\n",
    "\n",
    "# Targets to be predicted\n",
    "targets = train_df[train_df.columns[-3:]]\n",
    "\n",
    "# Cleaning an ugly columns\n",
    "train_df.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "test_df.drop(columns=['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very special to Xgboost as it likes non-continuous targets.\n",
    "d = {1:0.25, 4:1.0, 0:0.0, 2:0.50, 3:0.75}\n",
    "\n",
    "label_map = {0.0: 0, 0.25: 1, 0.5: 2, 0.75: 3, 1.0: 4}\n",
    "inv_label_map = {v:k for k,v in label_map.items()}\n",
    "\n",
    "# for t in ['Target_1', 'Target_2', 'Target_3']:\n",
    "#     targets[t] = targets[t].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df = pd.read_csv(train_datalink)\n",
    "\n",
    "features = [rf'Feature_{idx}' for idx in range(1, 251)]\n",
    "df_all = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare aggregated features\n",
    "# df_counts = df_all.groupby(['Moons'])[features].count().reset_index()\n",
    "df_mean = df_all.groupby(['Moons'])[features].mean().reset_index()\n",
    "df_std = df_all.groupby(['Moons'])[features].std().reset_index()\n",
    "\n",
    "df_all = df_all.merge(df_mean, on='Moons', how='left', suffixes=(\"\", \"_mean\")).merge(df_std, on='Moons', how='left', suffixes=(\"\", \"_std\"))\n",
    "\n",
    "for idx in range(1, 251):\n",
    "    df_all[rf'Feature_{idx}_deviation'] = df_all[rf\"Feature_{idx}\"] - df_all[rf\"Feature_{idx}_mean\"]\n",
    "\n",
    "for idx in range(1, 251):\n",
    "    df_all[rf\"Feature_{idx}_deviation_ratio\"] = np.where(df_all[rf\"Feature_{idx}_std\"] == 0, 0, df_all[rf'Feature_{idx}_deviation'] / df_all[rf\"Feature_{idx}_std\"])\n",
    "\n",
    "df_mean['Moons'] = df_mean['Moons'] + 1\n",
    "\n",
    "df_all = df_all.merge(df_mean, on='Moons', how='left', suffixes=(\"\", \"_mean_minus_1\"))\n",
    "\n",
    "df_all = df_all[df_all.Feature_250_mean_minus_1.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.iloc[-df_all.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119936, 1505), (70217, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_mean, df_std\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_all.drop(columns=['id', 'Moons'], inplace = True)\n",
    "test_len = test_df.shape[0]\n",
    "train_df = df_all.iloc[:-test_len]\n",
    "test_df = df_all.iloc[-test_len:]\n",
    "train_df.drop(columns=['Target_1', 'Target_2', 'Target_3'], inplace = True)\n",
    "test_df.drop(columns=['Target_1', 'Target_2', 'Target_3'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119936, 1503), (66095, 1500), (53841, 1500), (70217, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape, train_df.shape, test_df.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB for Target_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_model():\n",
    "    return lgb.LGBMRegressor(**{\n",
    "    'learning_rate': 0.01,\n",
    "#     'num_leaves': 31,\n",
    "#     'max_bin': 1023,\n",
    "#     'min_child_samples': 1000,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.2,\n",
    "    'feature_fraction': 0.9,\n",
    "#     'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.9,\n",
    "#     'objective': 'multiclass',\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':120,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0\n",
    "#     'num_classes': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.iloc[-train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "targets = targets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_df = orig_train_df.iloc[-train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119936, 1503), (66095, 1500), (53841, 1500), (66095, 3), (66095, 256))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape, train_df.shape, test_df.shape, targets.shape, orig_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "orig_train_df = orig_train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66095, 1500), (53841, 1500))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.11448\n",
      "[80]\tvalid_0's l2: 0.11384\n",
      "[120]\tvalid_0's l2: 0.113637\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.113637\n",
      "Spearman score for Fold 0: 0.14763660406787543\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114381\n",
      "[80]\tvalid_0's l2: 0.113707\n",
      "[120]\tvalid_0's l2: 0.113464\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.113464\n",
      "Spearman score for Fold 1: 0.15058404769958766\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114232\n",
      "[80]\tvalid_0's l2: 0.113445\n",
      "[120]\tvalid_0's l2: 0.113132\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.113132\n",
      "Spearman score for Fold 2: 0.16583100713519222\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114378\n",
      "[80]\tvalid_0's l2: 0.113656\n",
      "[120]\tvalid_0's l2: 0.113373\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.113373\n",
      "Spearman score for Fold 3: 0.1527849727268271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114091\n",
      "[80]\tvalid_0's l2: 0.113223\n",
      "[120]\tvalid_0's l2: 0.112818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.112818\n",
      "Spearman score for Fold 4: 0.1752317611273099\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114083\n",
      "[80]\tvalid_0's l2: 0.113208\n",
      "[120]\tvalid_0's l2: 0.112832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.112832\n",
      "Spearman score for Fold 5: 0.17428690760493004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.114145\n",
      "[80]\tvalid_0's l2: 0.113273\n",
      "[120]\tvalid_0's l2: 0.11285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.11285\n",
      "Spearman score for Fold 6: 0.17433549123575473\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[40]\tvalid_0's l2: 0.11426\n",
      "[80]\tvalid_0's l2: 0.113485\n",
      "[120]\tvalid_0's l2: 0.11317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[120]\tvalid_0's l2: 0.11317\n",
      "Spearman score for Fold 7: 0.16477380033844072\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame()\n",
    "results = []\n",
    "for col in ['Target_2']:\n",
    "    scores = []\n",
    "    MODELS = []\n",
    "    target = targets[col]\n",
    "    skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=11111)\n",
    "    for fold_, (train_indexes, valid_indexes) in enumerate(skf.split(train_df, target.map(label_map))):\n",
    "        y_pred = np.zeros(len(target)) \n",
    "        model = get_lgb_model()\n",
    "        model.fit( train_df.loc[train_indexes], target[train_indexes],\n",
    "                          eval_set = (train_df.loc[valid_indexes], target[valid_indexes]),\n",
    "                          verbose = 40,\n",
    "                          eval_metric='mse',\n",
    "                          early_stopping_rounds=25)\n",
    "        val_pred = model.predict(train_df.loc[valid_indexes])\n",
    "        y_pred[valid_indexes] = val_pred\n",
    "        score = spearman(target[valid_indexes], val_pred)\n",
    "        scores.append(score)\n",
    "        print(rf\"Spearman score for Fold {fold_}: {score}\")\n",
    "        MODELS.append( model )\n",
    "    preds = np.array([model.predict(test_df) for model in MODELS])\n",
    "    prediction[col] = preds.mean(axis=0)\n",
    "    results.append(rf\"Average Spearman score for {col}: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Target_1 and Target_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_df.values)\n",
    "test_data = scaler.transform(test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "epochs = 3\n",
    "learning_rate_init = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "num_features = train_data_scaled.shape[1]\n",
    "\n",
    "def get_model():\n",
    "    inp = keras.layers.Input((num_features,))\n",
    "    x = keras.layers.Reshape((num_features,1))(inp)\n",
    "    x = keras.layers.Conv1D(128,1,strides=1, activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv1D(32,1, activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv1D(16,1, activation='elu')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv1D(4,1, activation='elu')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Reshape((num_features*4,1))(x)\n",
    "    x = keras.layers.AveragePooling1D(2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    out = keras.layers.Dense(1)(x)\n",
    "    return keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch <= epochs*0.8:\n",
    "        return learning_rate_init\n",
    "    else:\n",
    "        return learning_rate_init * 0.1\n",
    "\n",
    "def train_NN(data, target):\n",
    "    optimizer = keras.optimizers.Adam(lr = learning_rate_init, decay = 0.00001)\n",
    "    model = get_model()\n",
    "    callbacks = []\n",
    "    callbacks.append(keras.callbacks.LearningRateScheduler(lr_scheduler))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    model.fit(data, target, epochs=epochs, verbose=1, batch_size=batch_size, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2066/2066 [==============================] - 16s 8ms/step - loss: 0.7394\n",
      "Epoch 2/3\n",
      "2066/2066 [==============================] - 17s 8ms/step - loss: 0.1592\n",
      "Epoch 3/3\n",
      "2066/2066 [==============================] - 16s 8ms/step - loss: 0.1218\n",
      "Epoch 1/3\n",
      "2066/2066 [==============================] - 16s 8ms/step - loss: 0.7304\n",
      "Epoch 2/3\n",
      "2066/2066 [==============================] - 16s 8ms/step - loss: 0.1572\n",
      "Epoch 3/3\n",
      "2066/2066 [==============================] - 17s 8ms/step - loss: 0.1224\n"
     ]
    }
   ],
   "source": [
    "model = train_NN(train_data_scaled, targets['Target_1'])\n",
    "prediction['Target_1'] = model.predict(test_data).ravel()\n",
    "model = train_NN(train_data_scaled, targets['Target_3'])\n",
    "prediction['Target_3'] = model.predict(test_data).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction[['Target_1', 'Target_2', 'Target_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction.to_csv('lgb_CNN2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = \"...\" # <- HERE\n",
    "\n",
    "# r = requests.post(\"https://hackathon.datacrunch.com/api/submission\",\n",
    "#     files = {\n",
    "#         \"file\": (\"x\", prediction.to_csv().encode('ascii'))\n",
    "#     },\n",
    "#     data = {\n",
    "#         \"apiKey\": API_KEY\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# if r.status_code == 200:\n",
    "#     print(\"Submission submitted :)\")\n",
    "# elif r.status_code == 423:\n",
    "#     print(\"ERR: Submissions are close\")\n",
    "#     print(\"The submissions are not enabled because the hackathon hasn't started yet or is already finished.\")\n",
    "#     print(\"Or the server is currently crunching the submitted files, please wait some time before retrying.\")\n",
    "# elif r.status_code == 422:\n",
    "#     print(\"ERR: API Key is missing or empty\")\n",
    "#     print(\"Did you forget to fill the API_KEY variable?\")\n",
    "# elif r.status_code == 404:\n",
    "#     print(\"ERR: Unknown API Key\")\n",
    "#     print(\"You should check that the provided API key is valid and is the same as the one you've received by email.\")\n",
    "# elif r.status_code == 400:\n",
    "#     print(\"ERR: The file must not be empty\")\n",
    "#     print(\"You have send a empty file.\")\n",
    "# elif r.status_code == 401:\n",
    "#     print(\"ERR: Your email hasn't been verified\")\n",
    "#     print(\"Please verify your email or contact a cruncher.\")\n",
    "# elif r.status_code == 429:\n",
    "#     print(\"ERR: Too many submissions\")\n",
    "# else:\n",
    "#     print(\"ERR: Server returned: \" + str(r.status_code))\n",
    "#     print(\"Ouch! It seems that we were not expecting this kind of result from the server, if the probleme persist, contact a cruncher.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[['Moons', 'Feature_189']].groupby('Moons')['Feature_189'].mean().plot()\n",
    "# df_all[['Moons', 'Feature_50']].groupby('Moons')['Feature_50'].mean().plot()\n",
    "# feat50_dict = df_all[['Moons', 'Feature_50']].groupby('Moons')['Feature_50'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Correlations\n",
    "# corrs = {}\n",
    "# for feat in [rf\"Feature_{idx}\" for idx in range(1, 251)]:\n",
    "#     corrs[feat] = np.corrcoef(train_df['Target_1'], train_df[feat] )[1][0]\n",
    "\n",
    "# sorted(corrs.items(),key=lambda x: -x[1])\n",
    "\n",
    "# # Check Correlations\n",
    "# corrs = {}\n",
    "# for feat in [rf\"Feature_{idx}\" for idx in range(1, 251)]:\n",
    "#     corrs[feat] = np.corrcoef(train_df['Target_3'], train_df[feat] )[1][0]\n",
    "\n",
    "# sorted(corrs.items(),key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.groupby('Moons').mean().reset_index()\n",
    "\n",
    "# df_all = df_all.drop('id', axis=1)\n",
    "\n",
    "# all_df_agg = df_all.groupby('Moons').mean().reset_index()\n",
    "\n",
    "# all_df_agg['Feature_58'].plot()\n",
    "\n",
    "# feat58_dict = pd.Series(all_df_agg.Feature_58.values, index=all_df_agg.Moons).to_dict()\n",
    "\n",
    "# feat94_dict = pd.Series(all_df_agg.Feature_94.values, index=all_df_agg.Moons).to_dict()\n",
    "\n",
    "# test_df['feat58'] = test_df.Moons.map(feat58_dict)\n",
    "\n",
    "# test_df['feat94'] = test_df.Moons.map(feat94_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
